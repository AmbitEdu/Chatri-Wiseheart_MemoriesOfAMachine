{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAexU2TUyIk7"
   },
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-HOtGg7VQe_"
   },
   "source": [
    "USER NOTE: If you intend to train the NLG model, make sure the colab is running on a GPU. You can check this under Edit -> Notebook Settings -> Hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "DC-3gwpdyK3G",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d48c78a2-54c4-4d59-d16f-9964538bb8e4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: fiftyone in /usr/local/lib/python3.8/dist-packages (0.18.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.0.2)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from fiftyone) (4.6.0.66)\n",
      "Requirement already satisfied: fiftyone-db<0.5,>=0.4 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.4.0)\n",
      "Requirement already satisfied: mongoengine==0.24.2 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.24.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.16.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.18.3)\n",
      "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.1.1)\n",
      "Requirement already satisfied: voxel51-eta<0.9,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.8.1)\n",
      "Requirement already satisfied: retrying in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.3.4)\n",
      "Requirement already satisfied: ndjson in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.3.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from fiftyone) (2022.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.21.6)\n",
      "Requirement already satisfied: fiftyone-brain<0.10,>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.9.2)\n",
      "Requirement already satisfied: pprintpp in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.4.0)\n",
      "Requirement already satisfied: xmltodict in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.13.0)\n",
      "Requirement already satisfied: sse-starlette<1,>=0.10.3 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.10.3)\n",
      "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (5.5.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.26.27)\n",
      "Requirement already satisfied: starlette==0.20.4 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.20.4)\n",
      "Requirement already satisfied: dacite>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.6.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.8.10)\n",
      "Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (3.1.2)\n",
      "Requirement already satisfied: kaleido in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.2.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from fiftyone) (6.0)\n",
      "Requirement already satisfied: sseclient-py<2,>=1.7.2 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.7.2)\n",
      "Requirement already satisfied: eventlet in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.33.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from fiftyone) (5.4.8)\n",
      "Requirement already satisfied: strawberry-graphql==0.138.1 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.138.1)\n",
      "Requirement already satisfied: Deprecated in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.2.13)\n",
      "Requirement already satisfied: hypercorn>=0.13.2 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (0.14.3)\n",
      "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (7.1.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from fiftyone) (1.3.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fiftyone) (21.3)\n",
      "Requirement already satisfied: motor>=2.3 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (3.1.1)\n",
      "Requirement already satisfied: argcomplete in /usr/local/lib/python3.8/dist-packages (from fiftyone) (2.0.0)\n",
      "Requirement already satisfied: aiofiles in /usr/local/lib/python3.8/dist-packages (from fiftyone) (22.1.0)\n",
      "Requirement already satisfied: pymongo>=3.11 in /usr/local/lib/python3.8/dist-packages (from fiftyone) (4.3.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from fiftyone) (3.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from fiftyone) (57.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.20.4->fiftyone) (4.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.20.4->fiftyone) (3.6.2)\n",
      "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (2.10)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from fiftyone-brain<0.10,>=0.9.2->fiftyone) (1.7.3)\n",
      "Requirement already satisfied: priority in /usr/local/lib/python3.8/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from hypercorn>=0.13.2->fiftyone) (1.2.0)\n",
      "Requirement already satisfied: h11 in /usr/local/lib/python3.8/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\n",
      "Requirement already satisfied: h2>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from hypercorn>=0.13.2->fiftyone) (4.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (6.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3->fiftyone) (2.0.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.14->fiftyone) (8.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=4.14->fiftyone) (1.15.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from pymongo>=3.11->fiftyone) (2.2.1)\n",
      "Requirement already satisfied: httpx>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.23.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (0.16.2)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.5.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.9.24)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (0.3.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (2.23.0)\n",
      "Requirement already satisfied: patool in /usr/local/lib/python3.8/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (1.12)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (1.5.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (1.25.11)\n",
      "Requirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (0.7)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (2.4.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from boto3->fiftyone) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3->fiftyone) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.27 in /usr/local/lib/python3.8/dist-packages (from boto3->fiftyone) (1.29.27)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
      "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.8/dist-packages (from eventlet->fiftyone) (2.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fiftyone) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->voxel51-eta<0.9,>=0.8.1->fiftyone) (3.0.4)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->fiftyone) (2.8.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->fiftyone) (2022.10.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->fiftyone) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->fiftyone) (2.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fiftyone) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0H_XBru453nS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "aa792904-77a5-4ce3-a5c0-2a1a2e126ff9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2xLeNqzo_AA8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as func\n",
    "from fiftyone import ViewField as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Lg1mGIrnKktr"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# content_path = '/content/drive/MyDrive/4 - Senior Year/First Semester/COMP 484/Project/CSCAPSTONE'\n",
    "# %cd '/content/drive/MyDrive/4 - Senior Year/First Semester/COMP 484/Project/CSCAPSTONE'\n",
    "# # content_path = 'drive/MyDrive/CSCAPSTONE'\n",
    "# # %cd 'drive/MyDrive/CSCAPSTONE'\n",
    "\n",
    "# # code dependencies (Text.py, LSTM_class.py, etc.) need to be in directory of content_path\n",
    "\n",
    "content_path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN6YH_m2xnP7"
   },
   "source": [
    "## Approach - Two-Step Pipeline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1u9LaiR_CKFf"
   },
   "source": [
    "### Vision Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waIUf-v2wzTF"
   },
   "source": [
    "#### Standard FiftyOne stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YvskOCyFp6vd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\xseth\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Downloading annotations to 'C:\\Users\\xseth\\fiftyone\\coco-2017\\tmp-download\\annotations_trainval2017.zip'\n",
      " 100% |██████████████████████████████████████████████|    1.9Gb/1.9Gb [26.9s elapsed, 0s remaining, 113.3Mb/s]      \n",
      "Extracting annotations to 'C:\\Users\\xseth\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Downloading images to 'C:\\Users\\xseth\\fiftyone\\coco-2017\\tmp-download\\val2017.zip'\n",
      " 100% |██████████████████████████████████████████████|    6.1Gb/6.1Gb [58.4s elapsed, 0s remaining, 115.5Mb/s]      \n",
      "Extracting images to 'C:\\Users\\xseth\\fiftyone\\coco-2017\\validation\\data'\n",
      "Writing annotations to 'C:\\Users\\xseth\\fiftyone\\coco-2017\\validation\\labels.json'\n",
      "Dataset info written to 'C:\\Users\\xseth\\fiftyone\\coco-2017\\info.json'\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 5000/5000 [28.1s elapsed, 0s remaining, 167.8 samples/s]      \n",
      "Dataset 'detector-recipe' created\n"
     ]
    }
   ],
   "source": [
    "### grab data\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    dataset_name=\"detector-recipe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ABUGcoYMyUbW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xseth\\mambaforge\\envs\\ai-gpu-attempt3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xseth\\mambaforge\\envs\\ai-gpu-attempt3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to C:\\Users\\xseth/.cache\\torch\\hub\\checkpoints\\fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "15.8%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "35.3%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "60.4%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "79.8%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vision_model ready\n"
     ]
    }
   ],
   "source": [
    "# Run the model on GPU if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load a pre-trained Faster R-CNN model\n",
    "vision_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# vision_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=Trueweights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
    "vision_model.to(device)\n",
    "vision_model.eval()\n",
    "\n",
    "print(\"vision_model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WGmL9SGs_uJJ"
   },
   "outputs": [],
   "source": [
    "# Choose a random subset of 100 samples to add predictions to\n",
    "# predictions_view = dataset.take(100, seed=51)  # TODO: remove this\n",
    "\n",
    "# Get class list\n",
    "classes = dataset.default_classes # TODO: include this in a preprocessing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ha7V70049-gT"
   },
   "outputs": [],
   "source": [
    "# classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nQu1bSQuSoh"
   },
   "source": [
    "#### New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "74NxUrSP6g7e"
   },
   "outputs": [],
   "source": [
    "def vision_predict_sample(sample, model):\n",
    "  \"\"\"Code decomposed from standard FiftyOne computer vision tutorial. Takes a\n",
    "  sample from a FiftyOne view, and uses a computer vision model to make a\n",
    "  prediction of what objects are present in the image.\"\"\"\n",
    "  # Load image\n",
    "  image = Image.open(sample.filepath)\n",
    "  image = func.to_tensor(image).to(device)\n",
    "  c, h, w = image.shape\n",
    "  # Perform inference\n",
    "  preds = model([image])[0]\n",
    "  labels = preds[\"labels\"].cpu().detach().numpy()\n",
    "  scores = preds[\"scores\"].cpu().detach().numpy()\n",
    "  boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
    "  # Convert detections to FiftyOne format\n",
    "  detections = []\n",
    "  for label, score, box in zip(labels, scores, boxes):\n",
    "    # Convert to [top-left-x, top-left-y, width, height]\n",
    "    # in relative coordinates in [0, 1] x [0, 1]\n",
    "    x1, y1, x2, y2 = box\n",
    "    rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "    detections.append(\n",
    "      fo.Detection(\n",
    "        label=classes[label],\n",
    "        bounding_box=rel_box,\n",
    "        confidence=score\n",
    "      )\n",
    "    )\n",
    "  # Save predictions to dataset\n",
    "  sample[\"predictions\"] = fo.Detections(detections=detections)\n",
    "  sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "H30YM9KEbi5F"
   },
   "outputs": [],
   "source": [
    "def sample_to_onehot(sample, model, conf_thresh=0.50):\n",
    "  \"\"\"Accepts a sample as input, and returns a one-hot vector representing the\n",
    "  classes detected in that sample image as an output. If predictions have not\n",
    "  already been made for this sample, then predictions are made.\n",
    "  Should return a one-hot vector, containing 1s for each class of object\n",
    "  that was detected. The 0-th position of the vector should always be 0 (this \n",
    "  is to match the convention that the class list, `classes`, always reserves\n",
    "  the index 0).\"\"\"\n",
    "  vec = [0 for i in range(0, len(classes))]\n",
    "  if not hasattr(sample, \"predictions\") or sample.predictions is None:\n",
    "    vision_predict_sample(sample, model)\n",
    "  predictions = sample.predictions\n",
    "  for detection in predictions.detections:\n",
    "    if detection['confidence'] > conf_thresh:\n",
    "      class_str = detection['label']\n",
    "      onehot_index = classes.index(class_str)\n",
    "      vec[onehot_index] = 1\n",
    "  # TODO: determine whether this information is easier to use as a list or a string\n",
    "  # one_hot = vec\n",
    "  one_hot = ''.join(map(str,vec))\n",
    "  return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LVOu5RvTBYjx"
   },
   "outputs": [],
   "source": [
    "def generate_onehot(sample, model, conf_thresh=0.5):\n",
    "  sample[\"one_hot\"] = sample_to_onehot(sample, vision_model)\n",
    "  sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u9VvLo3Y_IN3"
   },
   "outputs": [],
   "source": [
    "def onehot_to_labels(one_hot, classes):\n",
    "  labels = []\n",
    "  for i in range(len(one_hot)):\n",
    "    if int(one_hot[i]) == 1:\n",
    "      labels.append(classes[i])\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkoNeK8G9xxA"
   },
   "source": [
    "### NLG Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "F6oBwRY-qs8g"
   },
   "outputs": [],
   "source": [
    "# Import drive with text\n",
    "import functions as f\n",
    "\n",
    "from Text import *\n",
    "from LSTM_class import *\n",
    "\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm1s0uKZIA-x"
   },
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "J1BCoR3sAYeA"
   },
   "outputs": [],
   "source": [
    "path_train = content_path + '/data/train.txt'\n",
    "\n",
    "input_train = f.read_txt(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CC3saYjfA4GC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 1428900, distinct tokens: 42415\n",
      "number of sequences of length 4: 476299\n"
     ]
    }
   ],
   "source": [
    "# we create two training sets from the same corpus, one containing every word\n",
    "# of the corpus in the order they were written, and another containing all of\n",
    "# the words of the corpus in reverse order.\n",
    "\n",
    "max_len = 4\n",
    "step = 3\n",
    "\n",
    "text_train_forward = Text(input_train, reverse=False)\n",
    "text_train_reverse = Text(input_train, reverse=True)\n",
    "text_train_forward.tokens_info()\n",
    "\n",
    "seq_train_forward = Sequences(text_train_forward, max_len, step)\n",
    "seq_train_reverse = Sequences(text_train_reverse, max_len, step)\n",
    "seq_train_forward.sequences_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kzfmehuys5Xz"
   },
   "outputs": [],
   "source": [
    "def keyword_in_corpus(keyword, corpus=text_train_forward):\n",
    "  subwords = keyword.split(' ')  # some COCO keywords are actually two words\n",
    "  # TODO: two digit numbers should also be considered as two individual digits?\n",
    "  flag = True\n",
    "  for subword in subwords:\n",
    "    flag = flag and subword in corpus.token2ind.keys()\n",
    "  return flag\n",
    "\n",
    "def validate_corpus(corpus):\n",
    "  \"\"\"Returns a list of any tokens which might be detected in an image by the\n",
    "  vision model, but which are not in the vocabulary of this corpus. Ideally,\n",
    "  this list should only contain the number 0.\"\"\"\n",
    "  missing_vocab = []\n",
    "  present_vocab = []\n",
    "  for word in classes:\n",
    "    l = present_vocab if keyword_in_corpus(word, corpus) else missing_vocab\n",
    "    l.append(word)\n",
    "  return {'missing':missing_vocab, 'present':present_vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Q_T1JAgyti0U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus contains 70 MSCOCO keywords, out of 91 --- this is about 76.92 % attendance\n"
     ]
    }
   ],
   "source": [
    "attendance = validate_corpus(text_train_forward)\n",
    "print(\"corpus contains\", len(attendance['present']), \"MSCOCO keywords, out of\", len(classes), \"--- this is about\", int(10000*(len(attendance['present'])/len(classes)))/100, \"% attendance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dVocwWXgu0IO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motorcycle', 'airplane', 'fire hydrant', 'zebra', 'giraffe', 'backpack', 'frisbee', 'skis', 'snowboard', 'kite', 'skateboard', 'surfboard', 'broccoli', 'pizza', 'donut', 'tv', 'laptop', 'keyboard', 'microwave', 'toaster', 'teddy bear']\n"
     ]
    }
   ],
   "source": [
    "print(attendance['missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KRzQ3iO7HGJe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'entered', 'this', 'incarnation', 'on', 'March', 'the', 'twenty', '-', 'ninth']\n",
      "[22123, 26831, 6929, 37669, 21432, 23748, 35386, 9979, 378, 8464] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22123, 26831,  6929, 37669],\n",
       "       [37669, 21432, 23748, 35386],\n",
       "       [35386,  9979,   378,  8464]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_train_forward.tokens[:10])\n",
    "print(text_train_forward.tokens_ind[:10], '\\n')\n",
    "np.array(seq_train_forward.sequences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpIqWfADRkG8"
   },
   "source": [
    "The reverse sequences are not necessarily exact reverses of the forward sequences because the total number of tokens in the corpus doesn't necessariy divide evenly into 4-word subsequences, so one to three words may be left off of the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ddPdlOsnQVPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ninth', '-', 'twenty', 'the', 'March', 'on', 'incarnation', 'this', 'entered', 'I']\n",
      "[8467, 378, 9981, 35386, 23750, 21434, 37669, 6930, 26833, 22125] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4088, 38763,  8467,   378],\n",
       "       [  378,  9981, 35386, 23750],\n",
       "       [23750, 21434, 37669,  6930]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_train_reverse.tokens[-10:])\n",
    "print(text_train_reverse.tokens_ind[-10:], '\\n')\n",
    "np.array(seq_train_reverse.sequences[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-HH5_V7IC4w"
   },
   "source": [
    "#### model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Qd8bMwEh2hmy"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ak9zbcbqupo9"
   },
   "outputs": [],
   "source": [
    "target_nano = \"1670850237847602900\"  # chooses a particular version of the trained models, based on the nano time that the forward model finished training\n",
    "# loads the version of the token--index mappings that this particular model was trained on\n",
    "version_path = content_path + \"/out/model_\" + str(target_nano) + \"/\"\n",
    "token2ind_forward = json.load(open(version_path + \"word_mapping_forward.json\"))\n",
    "ind2token_forward = {value: key for (key, value) in token2ind_forward.items()}\n",
    "map_forward = (token2ind_forward, ind2token_forward)\n",
    "token2ind_reverse = json.load(open(version_path + \"word_mapping_reverse.json\"))\n",
    "ind2token_reverse = {value: key for (key, value) in token2ind_reverse.items()}\n",
    "map_reverse = (token2ind_reverse, ind2token_reverse)\n",
    "model_nlg_forward = models.load_model(version_path + \"model_nlg_forward\")\n",
    "model_nlg_reverse = models.load_model(version_path + \"model_nlg_reverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGa4IzJ8S_4X"
   },
   "source": [
    "#### prediction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kZm6tpWreiNU"
   },
   "outputs": [],
   "source": [
    "def produce_reversed_prediction(pred, text):\n",
    "  r0 = text.split(' ')\n",
    "  r0.reverse()\n",
    "  r0 = ' '.join(r0)\n",
    "  return pred.reverse_preprocess(r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xMBpf2Lki8jo"
   },
   "outputs": [],
   "source": [
    "def generate_reversed_prediction(pred, length=100, temperature=1):\n",
    "  text = pred.generate_sequence(length, temperature=temperature, ret_unprocessed=True)\n",
    "  return produce_reversed_prediction(pred, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "VPazAIPzfOvc"
   },
   "outputs": [],
   "source": [
    "def split_sentences(string):\n",
    "  \"\"\"Splits an input containing multiple sentences into a list of seperate\n",
    "  sentences, including the original punctuation.\"\"\"\n",
    "  # please god do not look at this dispicable regex\n",
    "  delimiters = '.!?'\n",
    "  l = []\n",
    "  l.append([])\n",
    "  for c in string:\n",
    "    l[-1].append(c)\n",
    "    if c in delimiters:\n",
    "      l.append([])\n",
    "  l2 = []\n",
    "  for slist in l:\n",
    "    s_l = ''.join(slist)\n",
    "    if not (s_l == '' or s_l == ' '):  # iffy attempt to address trailing whitespace\n",
    "      l2.append(s_l.strip())\n",
    "  return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zAW9DSQAgmsh"
   },
   "outputs": [],
   "source": [
    "def generate_descriptive_sentence(keyword, seq_len=100, temperature=1):\n",
    "  \"\"\"Given an input keyword contained in the corpus, generates a single sentence\n",
    "  of first-person English natural language which includes that keyword.\n",
    "  `seq_len` determines the maximum length of the subsequences generated when\n",
    "  generating the full target sentence. This is not necessarily the length of the\n",
    "  resulting sentence---typically, that sentence will be shorter, because only\n",
    "  one complete sentence from the final output is returned. The final output\n",
    "  will be no more than `2 * seq_len` tokens long (where our tokens are words and\n",
    "  punctuation). Low `seq_len` can occasionally result in truncated sentences,\n",
    "  wherein the model did not generate a full sentence before it reached the token\n",
    "  limit. High `seq_len`, however, is more computationally expensive for equal\n",
    "  outputs, because most of the additional tokens are not kept in the final\n",
    "  output. For this reason, a sequence length of around 50-150 is recommended.\n",
    "  `temperature` is a randomization factor between 0 and 1. The higher the\n",
    "  temperature, the more likely the model is to use unusual words from its corpus\n",
    "  (essentially, the more variety there will be in the output). Lower temperature\n",
    "  results in very stable and more gramatically correct language, but much less\n",
    "  variation and 'color' in the output.\"\"\"\n",
    "  # known issues:\n",
    "  #    sometimes produces really long sentences. Maybe reduce seq_len?\n",
    "  #    this may sometimes falsely cut sentence borders at Mr. or Ms. and other such abbreviations that include periods\n",
    "  pred_reverse = gen_pred(keyword, model_nlg_reverse, *map_reverse)\n",
    "  reverse_prediction = generate_reversed_prediction(pred_reverse, seq_len, temperature)\n",
    "  last_sentence_of_reverse = split_sentences(reverse_prediction)[-1]\n",
    "  pred_forward = gen_pred(last_sentence_of_reverse, model_nlg_forward, *map_forward)\n",
    "  forward_prediction = pred_forward.generate_sequence(seq_len, temperature=temperature)\n",
    "  first_sentence_of_forward = split_sentences(forward_prediction)[0]\n",
    "  # adds punctuation if the sentence was cut off early\n",
    "  if first_sentence_of_forward[-1] not in \".!?\":\n",
    "    first_sentence_of_forward += \".\"\n",
    "  return first_sentence_of_forward\n",
    "\n",
    "\n",
    "def gen_pred(prefix, model, token2ind, ind2token):\n",
    "  \"\"\"Convenience function that wraps the process of making a ModelPredict\n",
    "  object.\"\"\"\n",
    "  text_prefix= Text(prefix, token2ind, ind2token)\n",
    "  return ModelPredict(model, text_prefix, token2ind, ind2token, max_len, embedding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFAH5t3X8daN"
   },
   "source": [
    "### Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZQEv1RgFnQn"
   },
   "source": [
    "#### Synthesis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "alJJNnBDA2bV"
   },
   "outputs": [],
   "source": [
    "def find_classes_in(samples_view, vision_model, conf_thresh=0.50):\n",
    "  class_detections = []\n",
    "  for sample in samples_view:\n",
    "    generate_onehot(sample, vision_model, conf_thresh)\n",
    "    labels = onehot_to_labels(sample['one_hot'], classes)\n",
    "    for label in labels:  # but appending individual labels lets us easily filter out to only unique labels\n",
    "      class_detections.append(label)\n",
    "  return tuple(set(class_detections))  # removes duplicate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "R3XplVdlDa6V"
   },
   "outputs": [],
   "source": [
    "def generate_sentences_from(class_detections, temperature=0.7, max_sentences=3, seed=None):\n",
    "  # randomly reorders the keywords, so their corresponding sentences don't just\n",
    "  # appear in alphabetical order for every prediction.\n",
    "  if seed is None:\n",
    "    keywords = random.sample(class_detections, len(class_detections))\n",
    "  else:\n",
    "    random.seed(seed)\n",
    "    keywords = random.sample(class_detections, len(class_detections))\n",
    "  # only generates up to `max_sentences` sentences. This means that, in cases\n",
    "  # where there are many detections, some may be ignored. This process could\n",
    "  # be improved by, perhaps, prioritizing high confidence detections over low\n",
    "  # confidence detections, when deciding which to include and which to exclude.\n",
    "  sentences = []\n",
    "  for keyword in keywords:\n",
    "    if len(sentences) < max_sentences and keyword_in_corpus(keyword):\n",
    "      sentences.append(generate_descriptive_sentence(keyword, temperature=temperature))\n",
    "  return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lgBEsiTlEuy3"
   },
   "outputs": [],
   "source": [
    "def narrate_images(samples_view, conf_thresh=0.5, temperature=0.7, max_sentences=3, seed=None):\n",
    "  \"\"\"Given a set of input images, generates first-person narrative text based on\n",
    "  the detected contents of those images.\n",
    "  `conf_thresh` determines how confident the vision model must be in a detection\n",
    "  in order for it to be included in the list of classes which the natural\n",
    "  language model generates sentences for. If this is very high, some images\n",
    "  might not result in any output.\n",
    "  `temperature` determines how much the natural language model will deviate from\n",
    "  the most likely word selection. If this value is high, then the generate text\n",
    "  will almost always be gramatically correct, but is likely to be repetitive. If\n",
    "  the temperature is low, then the output will be much more varied, but it may\n",
    "  become ungrammatical, and is more likely to be nonsensical.\n",
    "  `max_sentences` is the maximum number of complete sentences which the natural\n",
    "  language model will attempt generate from the given set of images. If this is\n",
    "  high, the output could be very long, but will almost certainly include a\n",
    "  sentence for every detected class of object. If this value is low, the output\n",
    "  will be shorter and more concise, but may leave out some of the detections.\n",
    "  `seed` is a seed used for random processes, namely the random reordering of\n",
    "  keywords. This won't cause the same text to be generated on subsequent calls\n",
    "  (randomness is baked into the natural language model), but it will cause the\n",
    "  class detections to be presented in the same order each time.\"\"\"\n",
    "  class_detections = find_classes_in(samples_view, vision_model, conf_thresh)\n",
    "  sentences = generate_sentences_from(class_detections, temperature, max_sentences, seed)\n",
    "  paragraph = ' '.join(sentences)\n",
    "  return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "9ifqVkdsFOSr"
   },
   "outputs": [],
   "source": [
    "def narrate_n(num_images, conf_thresh=0.5, temperature=0.7, max_sentences=3, seed=None):\n",
    "  \"\"\"Chooses `num_images` images at random from the currently selected FiftyOne\n",
    "  dataset, and uses them to generate first-person narrative text.\"\"\"\n",
    "  samples_view = dataset.take(num_images) if seed is None else dataset.take(num_images, seed)\n",
    "  paragraph = narrate_images(samples_view, conf_thresh, temperature, max_sentences, seed)\n",
    "  return paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BuiLobUFp_O"
   },
   "source": [
    "#### Synthesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "0QDrA54RcksO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?context=ipython&subscription=e548018e-f297-4f3c-8854-b8ee0952353b\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e3c5e6b190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_view = dataset.take(3, seed=99)\n",
    "session = fo.launch_app(samples_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dmXjzLfOdFOy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After I was in England, when one person were at least of the Glasgow, Mary, I told him of the present time. Then she said, leave me in my face, went into the cup of their eyes. It was to me at some time, the meaning horse was more than the most pleasant, to let myself go to work, and I have the slow door of my own brothers of this thought of English, which is the fear of the world again, it is nearly to be to do, when the Governor was the office of the court the New York Hospital, and the New York.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrate_images(samples_view, seed=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "E9xv5OkaxNxJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22123"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train_forward.token2ind['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "34Q0H5NqylKe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22123"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = Text(open(path_train, 'r', encoding='utf-8').read())\n",
    "t1.token2ind['I']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "C-HH5_V7IC4w"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
