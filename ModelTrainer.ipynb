{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAexU2TUyIk7"
   },
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-HOtGg7VQe_"
   },
   "source": [
    "USER NOTE: If you intend to train the NLG model, make sure the colab is running on a GPU. You can check this under Edit -> Notebook Settings -> Hardware accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkoNeK8G9xxA"
   },
   "source": [
    "### NLG Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1670841561667,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "F6oBwRY-qs8g"
   },
   "outputs": [],
   "source": [
    "# Import drive with text\n",
    "import functions as f\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from Text import *\n",
    "from LSTM_class import *\n",
    "\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm1s0uKZIA-x"
   },
   "source": [
    "#### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1670841561667,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "J1BCoR3sAYeA"
   },
   "outputs": [],
   "source": [
    "content_path = '.'\n",
    "\n",
    "path_train = content_path + '/data/train.txt'\n",
    "\n",
    "input_train = f.read_txt(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 11598,
     "status": "aborted",
     "timestamp": 1670841561667,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "CC3saYjfA4GC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 1428900, distinct tokens: 42415\n",
      "number of sequences of length 4: 476299\n"
     ]
    }
   ],
   "source": [
    "# we create two training sets from the same corpus, one containing every word\n",
    "# of the corpus in the order they were written, and another containing all of\n",
    "# the words of the corpus in reverse order.\n",
    "\n",
    "max_len = 4\n",
    "step = 3\n",
    "\n",
    "text_train_forward = Text(input_train, reverse=False)\n",
    "text_train_reverse = Text(input_train, reverse=True)\n",
    "text_train_forward.tokens_info()\n",
    "\n",
    "seq_train_forward = Sequences(text_train_forward, max_len, step)\n",
    "seq_train_reverse = Sequences(text_train_reverse, max_len, step)\n",
    "seq_train_forward.sequences_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 11598,
     "status": "aborted",
     "timestamp": 1670841561668,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "kzfmehuys5Xz"
   },
   "outputs": [],
   "source": [
    "classes = ['0','person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','fire hydrant','12','stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','26','backpack','umbrella','29','30','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','45','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant','bed','66','dining table','68','69','toilet','71','tv','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','83','book','clock','vase','scissors','teddy bear','hair drier','toothbrush']\n",
    "\n",
    "def keyword_in_corpus(keyword, corpus=text_train_forward):\n",
    "  subwords = keyword.split(' ')  # some COCO keywords are actually two words\n",
    "  # TODO: two digit numbers should also be considered as two individual digits?\n",
    "  flag = True\n",
    "  for subword in subwords:\n",
    "    flag = flag and subword in corpus.token2ind.keys()\n",
    "  return flag\n",
    "\n",
    "def validate_corpus(corpus):\n",
    "  \"\"\"Returns a list of any tokens which might be detected in an image by the\n",
    "  vision model, but which are not in the vocabulary of this corpus. Ideally,\n",
    "  this list should only contain the number 0.\"\"\"\n",
    "  missing_vocab = []\n",
    "  present_vocab = []\n",
    "  for word in classes:\n",
    "    l = present_vocab if keyword_in_corpus(word, corpus) else missing_vocab\n",
    "    l.append(word)\n",
    "  return {'missing':missing_vocab, 'present':present_vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 11592,
     "status": "aborted",
     "timestamp": 1670841561668,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "Q_T1JAgyti0U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus contains 70 MSCOCO keywords, out of 91 --- this is about 76.92 % attendance\n"
     ]
    }
   ],
   "source": [
    "attendance = validate_corpus(text_train_forward)\n",
    "print(\"corpus contains\", len(attendance['present']), \"MSCOCO keywords, out of\", len(classes), \"--- this is about\", int(10000*(len(attendance['present'])/len(classes)))/100, \"% attendance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 11586,
     "status": "aborted",
     "timestamp": 1670841561668,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "dVocwWXgu0IO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motorcycle', 'airplane', 'fire hydrant', 'zebra', 'giraffe', 'backpack', 'frisbee', 'skis', 'snowboard', 'kite', 'skateboard', 'surfboard', 'broccoli', 'pizza', 'donut', 'tv', 'laptop', 'keyboard', 'microwave', 'toaster', 'teddy bear']\n"
     ]
    }
   ],
   "source": [
    "print(attendance['missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 11581,
     "status": "aborted",
     "timestamp": 1670841561669,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "KRzQ3iO7HGJe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'entered', 'this', 'incarnation', 'on', 'March', 'the', 'twenty', '-', 'ninth']\n",
      "[13025, 20355, 19524, 35998, 35687, 25002, 40649, 35065, 41940, 31725] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13025, 20355, 19524, 35998],\n",
       "       [35998, 35687, 25002, 40649],\n",
       "       [40649, 35065, 41940, 31725]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_train_forward.tokens[:10])\n",
    "print(text_train_forward.tokens_ind[:10], '\\n')\n",
    "np.array(seq_train_forward.sequences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpIqWfADRkG8"
   },
   "source": [
    "The reverse sequences are not necessarily exact reverses of the forward sequences because the total number of tokens in the corpus doesn't necessariy divide evenly into 4-word subsequences, so one to three words may be left off of the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 11576,
     "status": "aborted",
     "timestamp": 1670841561670,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "ddPdlOsnQVPQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ninth', '-', 'twenty', 'the', 'March', 'on', 'incarnation', 'this', 'entered', 'I']\n",
      "[31725, 41940, 35065, 40649, 25001, 35687, 35998, 19522, 20353, 13026] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7072,  5312, 31725, 41940],\n",
       "       [41940, 35065, 40649, 25001],\n",
       "       [25001, 35687, 35998, 19522]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_train_reverse.tokens[-10:])\n",
    "print(text_train_reverse.tokens_ind[-10:], '\\n')\n",
    "np.array(seq_train_reverse.sequences[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-HH5_V7IC4w"
   },
   "source": [
    "#### model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 11575,
     "status": "aborted",
     "timestamp": 1670841561670,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "62jF4R5XHir0"
   },
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "\n",
    "params = {\n",
    "  'sequence_length': max_len,\n",
    "  'vocab_size': len(text_train_forward),\n",
    "  'batch_size': batch_size,\n",
    "  'shuffle': True,\n",
    "  'embedding': True\n",
    "}\n",
    "\n",
    "train_generator_forward = TextDataGenerator(seq_train_forward.sequences, seq_train_forward.next_words, **params)\n",
    "train_generator_reverse = TextDataGenerator(seq_train_reverse.sequences, seq_train_reverse.next_words, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 11573,
     "status": "aborted",
     "timestamp": 1670841561670,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "3ZuLGBD0HlMh"
   },
   "outputs": [],
   "source": [
    "def lstm_model(sequence_length, vocab_size, layer_size, embedding=False):\n",
    "  model = models.Sequential()\n",
    "  if embedding:\n",
    "    model.add(layers.Embedding(vocab_size, layer_size))\n",
    "    model.add(layers.LSTM(layer_size))    \n",
    "  else:\n",
    "    model.add(layers.LSTM(layer_size, input_shape=(sequence_length, vocab_size)))\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  model.add(layers.Dense(vocab_size, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdg2OYLIH50K"
   },
   "source": [
    "#### model training (with embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 11573,
     "status": "aborted",
     "timestamp": 1670841561671,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "iuRFVd6N1oCu"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.RMSprop(lr=0.01)\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 11567,
     "status": "aborted",
     "timestamp": 1670841561671,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "JYySekexH1qw"
   },
   "outputs": [],
   "source": [
    "model_nlg_forward = lstm_model(max_len, len(text_train_forward), 512, embedding=True)\n",
    "model_nlg_forward.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 11567,
     "status": "aborted",
     "timestamp": 1670841561672,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "p8uYOboQ2Fwa"
   },
   "outputs": [],
   "source": [
    "nanotime = str(time.time_ns())  # uses the nano time as a simple version label\n",
    "version_path = content_path + '/out/model_' + str(nanotime) + \"/\"\n",
    "os.mkdir(version_path)\n",
    "\n",
    "with open(version_path + 'word_mapping_forward.json', 'w') as word_map_file:\n",
    "  word_map_file.write(json.dumps(text_train_forward.token2ind))\n",
    "with open(version_path + 'word_mapping_reverse.json', 'w') as word_map_file:\n",
    "  word_map_file.write(json.dumps(text_train_reverse.token2ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 11561,
     "status": "aborted",
     "timestamp": 1670841561673,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "JUFmoblzH4Hw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "116/116 [==============================] - 45s 355ms/step - loss: 6.5602\n",
      "Epoch 2/40\n",
      "116/116 [==============================] - 38s 330ms/step - loss: 5.5288\n",
      "Epoch 3/40\n",
      "116/116 [==============================] - 38s 329ms/step - loss: 5.2132\n",
      "Epoch 4/40\n",
      "116/116 [==============================] - 39s 332ms/step - loss: 4.9267\n",
      "Epoch 5/40\n",
      "116/116 [==============================] - 38s 329ms/step - loss: 4.6310\n",
      "Epoch 6/40\n",
      "116/116 [==============================] - 39s 334ms/step - loss: 4.3378\n",
      "Epoch 7/40\n",
      "116/116 [==============================] - 39s 338ms/step - loss: 4.0668\n",
      "Epoch 8/40\n",
      "116/116 [==============================] - 42s 360ms/step - loss: 3.8238\n",
      "Epoch 9/40\n",
      "116/116 [==============================] - 41s 351ms/step - loss: 3.6114\n",
      "Epoch 10/40\n",
      "116/116 [==============================] - 41s 351ms/step - loss: 3.4274\n",
      "Epoch 11/40\n",
      "116/116 [==============================] - 40s 344ms/step - loss: 3.2647\n",
      "Epoch 12/40\n",
      "116/116 [==============================] - 40s 347ms/step - loss: 3.1298\n",
      "Epoch 13/40\n",
      "116/116 [==============================] - 41s 352ms/step - loss: 3.0082\n",
      "Epoch 14/40\n",
      "116/116 [==============================] - 41s 349ms/step - loss: 2.9041\n",
      "Epoch 15/40\n",
      "116/116 [==============================] - 41s 351ms/step - loss: 2.8119\n",
      "Epoch 16/40\n",
      "116/116 [==============================] - 41s 349ms/step - loss: 2.7264\n",
      "Epoch 17/40\n",
      "116/116 [==============================] - 41s 352ms/step - loss: 2.6528\n",
      "Epoch 18/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.5822\n",
      "Epoch 19/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.5244\n",
      "Epoch 20/40\n",
      "116/116 [==============================] - 41s 354ms/step - loss: 2.4754\n",
      "Epoch 21/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 2.4288\n",
      "Epoch 22/40\n",
      "116/116 [==============================] - 42s 361ms/step - loss: 2.3848\n",
      "Epoch 23/40\n",
      "116/116 [==============================] - 41s 356ms/step - loss: 2.3500\n",
      "Epoch 24/40\n",
      "116/116 [==============================] - 41s 355ms/step - loss: 2.3181\n",
      "Epoch 25/40\n",
      "116/116 [==============================] - 41s 355ms/step - loss: 2.2837\n",
      "Epoch 26/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 2.2637\n",
      "Epoch 27/40\n",
      "116/116 [==============================] - 41s 352ms/step - loss: 2.2408\n",
      "Epoch 28/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.2169\n",
      "Epoch 29/40\n",
      "116/116 [==============================] - 41s 349ms/step - loss: 2.2018\n",
      "Epoch 30/40\n",
      "116/116 [==============================] - 41s 351ms/step - loss: 2.1869\n",
      "Epoch 31/40\n",
      "116/116 [==============================] - 42s 363ms/step - loss: 2.1698\n",
      "Epoch 32/40\n",
      "116/116 [==============================] - 43s 365ms/step - loss: 2.1618\n",
      "Epoch 33/40\n",
      "116/116 [==============================] - 43s 367ms/step - loss: 2.1526\n",
      "Epoch 34/40\n",
      "116/116 [==============================] - 42s 361ms/step - loss: 2.1439\n",
      "Epoch 35/40\n",
      "116/116 [==============================] - 42s 364ms/step - loss: 2.1345\n",
      "Epoch 36/40\n",
      "116/116 [==============================] - 42s 362ms/step - loss: 2.1298\n",
      "Epoch 37/40\n",
      "116/116 [==============================] - 41s 354ms/step - loss: 2.1275\n",
      "Epoch 38/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.1198\n",
      "Epoch 39/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.1186\n",
      "Epoch 40/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.1109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228c0449510>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nlg_forward.fit(train_generator_forward,\n",
    "              steps_per_epoch=len(train_generator_forward),\n",
    "              epochs=epochs,\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 11554,
     "status": "aborted",
     "timestamp": 1670841561673,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "uuBdX8_sM7Np"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/model_1670852439439527500/model_nlg_forward\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/model_1670852439439527500/model_nlg_forward\\assets\n"
     ]
    }
   ],
   "source": [
    "model_nlg_forward.save(version_path + 'model_nlg_forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 11553,
     "status": "aborted",
     "timestamp": 1670841561674,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "p59wWLRsat7W"
   },
   "outputs": [],
   "source": [
    "model_nlg_reverse = lstm_model(max_len, len(text_train_reverse), 512, embedding=True)\n",
    "model_nlg_reverse.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 11548,
     "status": "aborted",
     "timestamp": 1670841561674,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "yvUmwryjah5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "116/116 [==============================] - 42s 349ms/step - loss: 6.4765\n",
      "Epoch 2/40\n",
      "116/116 [==============================] - 40s 347ms/step - loss: 5.5010\n",
      "Epoch 3/40\n",
      "116/116 [==============================] - 41s 350ms/step - loss: 5.1614\n",
      "Epoch 4/40\n",
      "116/116 [==============================] - 40s 345ms/step - loss: 4.8660\n",
      "Epoch 5/40\n",
      "116/116 [==============================] - 41s 349ms/step - loss: 4.5700\n",
      "Epoch 6/40\n",
      "116/116 [==============================] - 40s 348ms/step - loss: 4.2832\n",
      "Epoch 7/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 4.0140\n",
      "Epoch 8/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 3.7753\n",
      "Epoch 9/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 3.5718\n",
      "Epoch 10/40\n",
      "116/116 [==============================] - 41s 356ms/step - loss: 3.3945\n",
      "Epoch 11/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 3.2390\n",
      "Epoch 12/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 3.1011\n",
      "Epoch 13/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 2.9834\n",
      "Epoch 14/40\n",
      "116/116 [==============================] - 42s 358ms/step - loss: 2.8727\n",
      "Epoch 15/40\n",
      "116/116 [==============================] - 42s 357ms/step - loss: 2.7802\n",
      "Epoch 16/40\n",
      "116/116 [==============================] - 41s 355ms/step - loss: 2.6940\n",
      "Epoch 17/40\n",
      "116/116 [==============================] - 42s 357ms/step - loss: 2.6214\n",
      "Epoch 18/40\n",
      "116/116 [==============================] - 42s 357ms/step - loss: 2.5533\n",
      "Epoch 19/40\n",
      "116/116 [==============================] - 42s 357ms/step - loss: 2.4952\n",
      "Epoch 20/40\n",
      "116/116 [==============================] - 42s 356ms/step - loss: 2.4423\n",
      "Epoch 21/40\n",
      "116/116 [==============================] - 41s 355ms/step - loss: 2.3958\n",
      "Epoch 22/40\n",
      "116/116 [==============================] - 41s 355ms/step - loss: 2.3513\n",
      "Epoch 23/40\n",
      "116/116 [==============================] - 42s 359ms/step - loss: 2.3168\n",
      "Epoch 24/40\n",
      "116/116 [==============================] - 42s 360ms/step - loss: 2.2875\n",
      "Epoch 25/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.2642\n",
      "Epoch 26/40\n",
      "116/116 [==============================] - 41s 350ms/step - loss: 2.2392\n",
      "Epoch 27/40\n",
      "116/116 [==============================] - 41s 351ms/step - loss: 2.2195\n",
      "Epoch 28/40\n",
      "116/116 [==============================] - 41s 349ms/step - loss: 2.2060\n",
      "Epoch 29/40\n",
      "116/116 [==============================] - 41s 348ms/step - loss: 2.1899\n",
      "Epoch 30/40\n",
      "116/116 [==============================] - 41s 352ms/step - loss: 2.1713\n",
      "Epoch 31/40\n",
      "116/116 [==============================] - 41s 350ms/step - loss: 2.1619\n",
      "Epoch 32/40\n",
      "116/116 [==============================] - 41s 352ms/step - loss: 2.1563\n",
      "Epoch 33/40\n",
      "116/116 [==============================] - 41s 350ms/step - loss: 2.1490\n",
      "Epoch 34/40\n",
      "116/116 [==============================] - 41s 351ms/step - loss: 2.1419\n",
      "Epoch 35/40\n",
      "116/116 [==============================] - 41s 350ms/step - loss: 2.1362\n",
      "Epoch 36/40\n",
      "116/116 [==============================] - 41s 348ms/step - loss: 2.1288\n",
      "Epoch 37/40\n",
      "116/116 [==============================] - 41s 350ms/step - loss: 2.1307\n",
      "Epoch 38/40\n",
      "116/116 [==============================] - 41s 352ms/step - loss: 2.1279\n",
      "Epoch 39/40\n",
      "116/116 [==============================] - 41s 350ms/step - loss: 2.1288\n",
      "Epoch 40/40\n",
      "116/116 [==============================] - 41s 353ms/step - loss: 2.1235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228a7d5f430>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nlg_reverse.fit(train_generator_reverse,\n",
    "              steps_per_epoch=len(train_generator_reverse),\n",
    "              epochs=epochs,\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 11540,
     "status": "aborted",
     "timestamp": 1670841561674,
     "user": {
      "displayName": "Seth Wiseheart",
      "userId": "05536392614089282243"
     },
     "user_tz": 360
    },
    "id": "q1uTLtUManAJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/model_1670852439439527500/model_nlg_reverse\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/model_1670852439439527500/model_nlg_reverse\\assets\n"
     ]
    }
   ],
   "source": [
    "model_nlg_reverse.save(version_path + 'model_nlg_reverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12139450098239292644\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6277824512\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4768076950934225043\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UAexU2TUyIk7",
    "6nQu1bSQuSoh",
    "kUCrWxjyuVGk"
   ],
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
